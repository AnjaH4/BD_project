{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in the file: 13330575\n",
      "Reading 133305 rows (1% of the total rows)\n",
      "  Summons Number,Plate ID,Registration State,Plate Type,Issue Date,Violation Code,Vehicle Body Type,Vehicle Make,Issuing Agency,Street Code1,Street Code2,Street Code3,Vehicle Expiration Date,Violation Location,Violation Precinct,Issuer Precinct,Issuer Code,Issuer Command,Issuer Squad,Violation Time,Time First Observed,Violation County,Violation In Front Of Or Opposite,House Number,Street Name,Intersecting Street,Date First Observed,Law Section,Sub Division,Violation Legal Code,Days Parking In Effect    ,From Hours In Effect,To Hours In Effect,Vehicle Color,Unregistered Vehicle?,Vehicle Year,Meter Number,Feet From Curb,Violation Post Code,Violation Description,No Standing or Stopping Violation,Hydrant Violation,Double Parking Violation\n",
      "0  1159637337,KZH2758,NY,PAS,06/09/2023,67,VAN,HO...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "1  1252960645,JPD8746,NY,PAS,06/30/2023,87,SUBN,L...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "2  1252960669,JPD8746,NY,PAS,06/30/2023,31,SUBN,L...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "3  1252994126,MBH9245,99,PAS,07/06/2023,20,SDN,KI...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "4  1252994175,MBH9245,PA,PAS,07/08/2023,40,SDN,KI...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Path to your Parquet file\n",
    "parquet_file_path = 'data/Parking_Violations_Issued_-_Fiscal_Year_2024_20240524.parquet'\n",
    "\n",
    "# Step 1: Determine the total number of rows\n",
    "parquet_file = pq.ParquetFile(parquet_file_path)\n",
    "total_rows = parquet_file.metadata.num_rows\n",
    "\n",
    "# Step 2: Calculate the number of rows to read (1% of the total rows)\n",
    "rows_to_read = max(1, total_rows // 100)\n",
    "\n",
    "# Step 3: Read the first 'rows_to_read' rows\n",
    "df = pd.read_parquet(parquet_file_path, engine='pyarrow', columns=None)\n",
    "df_sample = df.head(rows_to_read)\n",
    "\n",
    "print(f\"Total rows in the file: {total_rows}\")\n",
    "print(f\"Reading {rows_to_read} rows (1% of the total rows)\")\n",
    "\n",
    "print(df_sample.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pd.read_csv('data/NYTickets/2014.csv').to_hdf('data/NYTickets/2014.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anjah/miniconda3/envs/bd_project/lib/python3.9/site-packages/dask/dataframe/io/csv.py:195: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = reader(bio, **kwargs)\n",
      "/home/anjah/miniconda3/envs/bd_project/lib/python3.9/site-packages/dask/dataframe/io/csv.py:195: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = reader(bio, **kwargs)\n",
      "/home/anjah/miniconda3/envs/bd_project/lib/python3.9/site-packages/dask/dataframe/io/csv.py:195: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = reader(bio, **kwargs)\n",
      "/home/anjah/miniconda3/envs/bd_project/lib/python3.9/site-packages/dask/dataframe/io/csv.py:195: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = reader(bio, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing data/NYTickets/2016.csv: cannot match existing table structure for [Summons Number,Violation Code,Street Code1,Street Code2,Street Code3,Vehicle Expiration Date,Violation Precinct,Issuer Precinct,Issuer Code,Vehicle Year,Feet From Curb] on appending data\n",
      "Converted data/NYTickets/2017.csv to data/NYTickets/2017.h5\n",
      "Converted data/NYTickets/2019.csv to data/NYTickets/2019.h5\n",
      "Converted data/NYTickets/2018.csv to data/NYTickets/2018.h5\n",
      "Converted data/NYTickets/2020.csv to data/NYTickets/2020.h5\n",
      "Error processing data/NYTickets/2021.csv: Trying to store a string with len [48] in [values_block_1] column but\n",
      "this column has a limit of [30]!\n",
      "Consider using min_itemsize to preset the sizes on these columns\n",
      "Error processing data/NYTickets/2014.csv: cannot match existing table structure for [Number] on appending data\n",
      "Error processing data/NYTickets/2015.csv: Trying to store a string with len [42] in [values_block_2] column but\n",
      "this column has a limit of [30]!\n",
      "Consider using min_itemsize to preset the sizes on these columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anjah/miniconda3/envs/bd_project/lib/python3.9/site-packages/dask/dataframe/io/csv.py:195: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = reader(bio, **kwargs)\n",
      "/home/anjah/miniconda3/envs/bd_project/lib/python3.9/site-packages/dask/dataframe/io/csv.py:195: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = reader(bio, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing data/NYTickets/2024_april.csv: Trying to store a string with len [71] in [values_block_1] column but\n",
      "this column has a limit of [65]!\n",
      "Consider using min_itemsize to preset the sizes on these columns\n",
      "Error processing data/NYTickets/2023.csv: Trying to store a string with len [71] in [values_block_1] column but\n",
      "this column has a limit of [65]!\n",
      "Consider using min_itemsize to preset the sizes on these columns\n",
      "Converted data/NYTickets/2022.csv to data/NYTickets/2022.h5\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Specify the path to the CSV files\n",
    "csv_files = glob.glob('data/NYTickets/*.csv')\n",
    "\n",
    "# Define the data types for each column\n",
    "dtype = {\n",
    "    'Summons Number': 'object',\n",
    "    'Plate ID': 'object',\n",
    "    'Registration State': 'object',\n",
    "    'Plate Type': 'object',\n",
    "    'Issue Date': 'object',\n",
    "    'Violation Code': 'object',\n",
    "    'Vehicle Body Type': 'object',\n",
    "    'Vehicle Make': 'object',\n",
    "    'Issuing Agency': 'object',\n",
    "    'Street Code1': 'object',\n",
    "    'Street Code2': 'object',\n",
    "    'Street Code3': 'object',\n",
    "    'Vehicle Expiration Date': 'object',\n",
    "    'Violation Location': 'object',\n",
    "    'Violation Precinct': 'object',\n",
    "    'Issuer Precinct': 'object',\n",
    "    'Issuer Code': 'object',\n",
    "    'Issuer Command': 'object',\n",
    "    'Issuer Squad': 'object',\n",
    "    'Violation Time': 'object',\n",
    "    'Time First Observed': 'object',\n",
    "    'Violation County': 'object',\n",
    "    'Violation In Front Of Or Opposite': 'object',\n",
    "    'Number': 'object',\n",
    "    'Street': 'object',\n",
    "    'Intersecting Street': 'object',\n",
    "    'Date First Observed': 'object',\n",
    "    'Law Section': 'object',\n",
    "    'Sub Division': 'object',\n",
    "    'Violation Legal Code': 'object',\n",
    "    'Days Parking In Effect': 'object',\n",
    "    'From Hours In Effect': 'object',\n",
    "    'To Hours In Effect': 'object',\n",
    "    'Vehicle Color': 'object',\n",
    "    'Unregistered Vehicle?': 'object',\n",
    "    'Vehicle Year': 'object',\n",
    "    'Meter Number': 'object',\n",
    "    'Feet From Curb': 'object',\n",
    "    'Violation Post Code': 'object',\n",
    "    'Violation Description': 'object',\n",
    "    'No Standing or Stopping Violation': 'object',\n",
    "    'Hydrant Violation': 'object',\n",
    "    'Double Parking Violation': 'object',\n",
    "    'House Number': 'object'\n",
    "}\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    try:\n",
    "        # Read the CSV file into a Dask DataFrame with specified dtypes\n",
    "        ddf = dd.read_csv(csv_file, dtype=dtype)\n",
    "\n",
    "        # Coerce numeric columns\n",
    "        numeric_columns = ['Summons Number', 'Violation Code', 'Street Code1', 'Street Code2', 'Street Code3', \n",
    "                           'Vehicle Expiration Date', 'Violation Precinct', 'Issuer Precinct', 'Issuer Code', \n",
    "                           'Number', 'Vehicle Year', 'Feet From Curb']\n",
    "        for col in numeric_columns:\n",
    "            if col in ddf.columns:\n",
    "                ddf[col] = dd.to_numeric(ddf[col], errors='coerce')\n",
    "\n",
    "        # Define the output HDF5 file path\n",
    "        hdf5_file = os.path.join('data/NYTickets', os.path.basename(csv_file).replace('.csv', '.h5'))\n",
    "\n",
    "        # Write the DataFrame to HDF5\n",
    "        ddf.to_hdf(hdf5_file, key='data', mode='w', format='table')\n",
    "\n",
    "        print(f'Converted {csv_file} to {hdf5_file}')\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Error processing {csv_file}: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_csv('data/NYTickets/2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dtypes of columns of ddf to dictionary\n",
    "# read 2017.h5 data\n",
    "ddf = dd.read_hdf('data/NYTickets/2017.h5', key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ddf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bd_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
